"""
ë°°í¬ëœ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°ì´í„°ë¥¼ ë¡œì»¬ë¡œ ê°€ì ¸ì˜¤ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš© ë°©ë²•:
1. ë°°í¬ëœ DATABASE_URLì„ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥
2. python export_production_db.py ì‹¤í–‰
3. ë°ì´í„°ê°€ CSV íŒŒì¼ë¡œ ì €ì¥ë˜ê±°ë‚˜ ë¡œì»¬ SQLite DBë¡œ ë³µì‚¬ë¨
"""
import os
import sys
import csv
import json
from datetime import datetime

# ë°°í¬ëœ DATABASE_URL ì…ë ¥ (Vercel í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ì§ì ‘ ì…ë ¥)
# 
# Vercelì—ì„œ DATABASE_URL í™•ì¸ ë°©ë²•:
# 1. https://vercel.com ì ‘ì† í›„ ë¡œê·¸ì¸
# 2. í”„ë¡œì íŠ¸ ì„ íƒ (jjaysolution.com ë˜ëŠ” 3pl-return-management)
# 3. ìƒë‹¨ ë©”ë‰´ì—ì„œ "Settings" í´ë¦­
# 4. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ "Environment Variables" í´ë¦­
# 5. "DATABASE_URL" ì°¾ê¸° (ê°’ì´ ë§ˆìŠ¤í‚¹ë˜ì–´ ìˆìœ¼ë©´ "Reveal" ë²„íŠ¼ í´ë¦­)
# 6. ì „ì²´ ì—°ê²° ë¬¸ìì—´ ë³µì‚¬ (postgresql://... í˜•ì‹)
#
# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •:
# Windows PowerShell: $env:PRODUCTION_DATABASE_URL="postgresql://..."
# Windows CMD: set PRODUCTION_DATABASE_URL=postgresql://...
# Linux/Mac: export PRODUCTION_DATABASE_URL="postgresql://..."

PRODUCTION_DATABASE_URL = os.environ.get('PRODUCTION_DATABASE_URL')

if not PRODUCTION_DATABASE_URL:
    print('\n' + '=' * 60)
    print('DATABASE_URL ì…ë ¥ í•„ìš”')
    print('=' * 60)
    print('\nVercelì—ì„œ DATABASE_URL í™•ì¸ ë°©ë²•:')
    print('1. https://vercel.com ì ‘ì† í›„ ë¡œê·¸ì¸')
    print('2. í”„ë¡œì íŠ¸ ì„ íƒ (jjaysolution.com ë˜ëŠ” 3pl-return-management)')
    print('3. ìƒë‹¨ ë©”ë‰´ì—ì„œ "Settings" í´ë¦­')
    print('4. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ "Environment Variables" í´ë¦­')
    print('5. "DATABASE_URL" ì°¾ê¸° (ê°’ì´ ë§ˆìŠ¤í‚¹ë˜ì–´ ìˆìœ¼ë©´ "Reveal" ë²„íŠ¼ í´ë¦­)')
    print('6. ì „ì²´ ì—°ê²° ë¬¸ìì—´ ë³µì‚¬ (postgresql://... í˜•ì‹)')
    print('\në˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •:')
    print('  Windows PowerShell: $env:PRODUCTION_DATABASE_URL="postgresql://..."')
    print('  Windows CMD: set PRODUCTION_DATABASE_URL=postgresql://...')
    print('  Linux/Mac: export PRODUCTION_DATABASE_URL="postgresql://..."')
    print('\n' + '-' * 60)
    print('\nâš ï¸ ì£¼ì˜: DATABASE_URL ê°’ë§Œ ì…ë ¥í•˜ì„¸ìš” (ëª…ë ¹ì–´ ì „ì²´ê°€ ì•„ë‹™ë‹ˆë‹¤)')
    print('   ì˜ˆ: postgresql://user:password@host:port/database?sslmode=require')
    print('   âŒ ì˜ëª»ëœ ì…ë ¥: $env:PRODUCTION_DATABASE_URL="postgresql://..."')
    print('   âœ… ì˜¬ë°”ë¥¸ ì…ë ¥: postgresql://user:password@host:port/database?sslmode=require')
    print('\n' + '-' * 60)
    user_input = input('\në°°í¬ëœ DATABASE_URLì„ ì…ë ¥í•˜ì„¸ìš”: ').strip()
    
    # ì‚¬ìš©ìê°€ ëª…ë ¹ì–´ ì „ì²´ë¥¼ ì…ë ¥í•œ ê²½ìš° ìë™ìœ¼ë¡œ ì¶”ì¶œ
    if user_input.startswith('$env:PRODUCTION_DATABASE_URL=') or user_input.startswith('set PRODUCTION_DATABASE_URL=') or user_input.startswith('export PRODUCTION_DATABASE_URL='):
        # ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ë¶€ë¶„ ì¶”ì¶œ
        import re
        match = re.search(r'["\'](postgresql://[^"\']+)["\']', user_input)
        if match:
            PRODUCTION_DATABASE_URL = match.group(1)
            print(f'\nâœ… DATABASE_URL ìë™ ì¶”ì¶œ: {PRODUCTION_DATABASE_URL[:50]}...')
        else:
            # ë“±í˜¸ ë’¤ì˜ ê°’ ì¶”ì¶œ
            if '=' in user_input:
                PRODUCTION_DATABASE_URL = user_input.split('=', 1)[1].strip('"\'')
            else:
                PRODUCTION_DATABASE_URL = user_input
    else:
        PRODUCTION_DATABASE_URL = user_input.strip('"\'')

if not PRODUCTION_DATABASE_URL:
    print('âŒ DATABASE_URLì´ í•„ìš”í•©ë‹ˆë‹¤.')
    sys.exit(1)

try:
    import psycopg2
    from psycopg2.extras import RealDictCursor
except ImportError:
    print('âŒ psycopg2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install psycopg2-binary ì‹¤í–‰í•˜ì„¸ìš”.')
    sys.exit(1)

def connect_to_production_db():
    """ë°°í¬ëœ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°"""
    try:
        # SSL ëª¨ë“œ ì¶”ê°€
        if 'sslmode' not in PRODUCTION_DATABASE_URL and 'sslmode=' not in PRODUCTION_DATABASE_URL:
            if '?' in PRODUCTION_DATABASE_URL:
                conn = psycopg2.connect(PRODUCTION_DATABASE_URL + '&sslmode=require')
            else:
                conn = psycopg2.connect(PRODUCTION_DATABASE_URL + '?sslmode=require')
        else:
            conn = psycopg2.connect(PRODUCTION_DATABASE_URL)
        print('âœ… ë°°í¬ëœ ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.')
        return conn
    except Exception as e:
        print(f'âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}')
        sys.exit(1)

def get_all_tables(conn):
    """ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    cursor = conn.cursor()
    cursor.execute("""
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_type = 'BASE TABLE'
        ORDER BY table_name
    """)
    tables = [row[0] for row in cursor.fetchall()]
    cursor.close()
    return tables

def export_table_to_csv(conn, table_name, output_dir='exported_data'):
    """í…Œì´ë¸” ë°ì´í„°ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    cursor = conn.cursor(cursor_factory=RealDictCursor)
    try:
        cursor.execute(f'SELECT * FROM {table_name} ORDER BY id')
        rows = cursor.fetchall()
        
        if not rows:
            print(f'   âš ï¸ {table_name}: ë°ì´í„° ì—†ìŒ')
            return 0
        
        # CSV íŒŒì¼ë¡œ ì €ì¥
        csv_file = os.path.join(output_dir, f'{table_name}.csv')
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            if rows:
                writer = csv.DictWriter(f, fieldnames=rows[0].keys())
                writer.writeheader()
                for row in rows:
                    writer.writerow(dict(row))
        
        print(f'   âœ… {table_name}: {len(rows)}ê±´ â†’ {csv_file}')
        return len(rows)
    except Exception as e:
        print(f'   âŒ {table_name}: ì˜¤ë¥˜ - {e}')
        return 0
    finally:
        cursor.close()

def export_table_to_json(conn, table_name, output_dir='exported_data'):
    """í…Œì´ë¸” ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    cursor = conn.cursor(cursor_factory=RealDictCursor)
    try:
        cursor.execute(f'SELECT * FROM {table_name} ORDER BY id')
        rows = cursor.fetchall()
        
        if not rows:
            return 0
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        json_file = os.path.join(output_dir, f'{table_name}.json')
        data = []
        for row in rows:
            row_dict = dict(row)
            # ë‚ ì§œ ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            for key, value in row_dict.items():
                if isinstance(value, datetime):
                    row_dict[key] = value.isoformat()
            data.append(row_dict)
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f'   âœ… {table_name}: {len(rows)}ê±´ â†’ {json_file}')
        return len(rows)
    except Exception as e:
        print(f'   âŒ {table_name}: ì˜¤ë¥˜ - {e}')
        return 0
    finally:
        cursor.close()

def copy_to_local_sqlite(conn, output_db='data.db'):
    """PostgreSQL ë°ì´í„°ë¥¼ ë¡œì»¬ SQLiteë¡œ ë³µì‚¬ (ë¡œì»¬ ê°œë°œìš© data.dbì— ì§ì ‘ ë³µì‚¬)"""
    import sqlite3
    
    print(f'\nğŸ“¦ ë°°í¬ëœ ë°ì´í„°ë¥¼ ë¡œì»¬ data.dbë¡œ ë³µì‚¬ ì¤‘...')
    print(f'   (ë¡œì»¬ ì„œë²„ ì‹¤í–‰ ì‹œ ë°°í¬ëœ ìƒíƒœì™€ ë™ì¼í•˜ê²Œ ë³´ì´ë„ë¡)')
    
    # SQLite ì—°ê²°
    sqlite_conn = sqlite3.connect(output_db)
    sqlite_cursor = sqlite_conn.cursor()
    
    tables = get_all_tables(conn)
    total_rows = 0
    
    for table_name in tables:
        try:
            # PostgreSQLì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            pg_cursor = conn.cursor(cursor_factory=RealDictCursor)
            pg_cursor.execute(f'SELECT * FROM {table_name} ORDER BY id')
            rows = pg_cursor.fetchall()
            pg_cursor.close()
            
            if not rows:
                print(f'   âš ï¸ {table_name}: ë°ì´í„° ì—†ìŒ')
                continue
            
            # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ê°€ì ¸ì˜¤ê¸°
            pg_cursor = conn.cursor()
            pg_cursor.execute(f"""
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_name = '{table_name}'
                ORDER BY ordinal_position
            """)
            columns = pg_cursor.fetchall()
            pg_cursor.close()
            
            # SQLite í…Œì´ë¸” ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
            column_defs = []
            for col_name, col_type in columns:
                if 'int' in col_type.lower():
                    column_defs.append(f'{col_name} INTEGER')
                elif 'text' in col_type.lower() or 'varchar' in col_type.lower():
                    column_defs.append(f'{col_name} TEXT')
                elif 'timestamp' in col_type.lower() or 'date' in col_type.lower():
                    column_defs.append(f'{col_name} TEXT')
                else:
                    column_defs.append(f'{col_name} TEXT')
            
            # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
            sqlite_cursor.execute(f'DROP TABLE IF EXISTS {table_name}')
            
            # í…Œì´ë¸” ìƒì„±
            create_sql = f'CREATE TABLE {table_name} ({", ".join(column_defs)})'
            sqlite_cursor.execute(create_sql)
            
            # ë°ì´í„° ì‚½ì…
            if rows:
                col_names = list(rows[0].keys())
                placeholders = ','.join(['?' for _ in col_names])
                insert_sql = f'INSERT INTO {table_name} ({",".join(col_names)}) VALUES ({placeholders})'
                
                for row in rows:
                    values = []
                    for col in col_names:
                        val = dict(row).get(col)
                        if isinstance(val, datetime):
                            val = val.isoformat()
                        values.append(val)
                    sqlite_cursor.execute(insert_sql, values)
            
            sqlite_conn.commit()
            print(f'   âœ… {table_name}: {len(rows)}ê±´ ë³µì‚¬ ì™„ë£Œ')
            total_rows += len(rows)
        except Exception as e:
            print(f'   âŒ {table_name}: ì˜¤ë¥˜ - {e}')
            import traceback
            traceback.print_exc()
    
    sqlite_conn.close()
    print(f'\nâœ… ì´ {total_rows}ê±´ì˜ ë°ì´í„°ê°€ {output_db}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.')
    return total_rows

def main():
    print('=' * 60)
    print('ë°°í¬ëœ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ë‚´ë³´ë‚´ê¸°')
    print('=' * 60)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    conn = connect_to_production_db()
    
    try:
        # í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        tables = get_all_tables(conn)
        print(f'\nğŸ“‹ ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ')
        for table in tables:
            print(f'   - {table}')
        
        # ë°°í¬ëœ ë°ì´í„°ë¥¼ ë¡œì»¬ data.dbë¡œ ë³µì‚¬ (ë¡œì»¬ ê°œë°œ í™˜ê²½ê³¼ ë™ì¼í•˜ê²Œ)
        print('\nğŸ“¦ ë°°í¬ëœ ë°ì´í„°ë¥¼ ë¡œì»¬ data.dbë¡œ ë³µì‚¬ ì¤‘...')
        print('   (ë¡œì»¬ ì„œë²„ ì‹¤í–‰ ì‹œ ë°°í¬ëœ ìƒíƒœì™€ ë™ì¼í•˜ê²Œ ë³´ì´ë„ë¡)')
        copy_to_local_sqlite(conn)
        
        print('\nâœ… ì™„ë£Œ! ì´ì œ ë¡œì»¬ì—ì„œ python app.py ì‹¤í–‰í•˜ë©´ ë°°í¬ëœ ë°ì´í„°ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
    
    finally:
        conn.close()
        print('\nâœ… ì‘ì—… ì™„ë£Œ!')

if __name__ == '__main__':
    main()

